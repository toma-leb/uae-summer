# Natural Language Processing

Word Embedings/Transformation/Encoding  : 
- Basic Filtering (remove quote and comas etc...)
- Tokenisation
- Multiwords grouping
- Stopwords filtering (removing "that" etc...)
- Results

## Bag Of Words

Number of appirance of a world in a text. The matrix is all the worlds of a language

## Term Frequency-Inverse Document Frequency (TF-IDF)

1. TF : Number of appirance of a world over the number of worlds in the sentence. 
2. IDF : Identifie the importance of a world
3. Classication, clustrerisation, comparison

## Lexical Ambiguity

The same chain of caracter (word) can have differents meaning, depending on the context.

## word2vec

king + woman - man = queen

It's a vector representation of words, the proximity of the next world will have importance on the encoding.